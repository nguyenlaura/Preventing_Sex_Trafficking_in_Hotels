{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "import os\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mchain_info.csv\u001b[m\u001b[m hotel_info.csv test_set.csv   train_set.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls input/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('input/dataset/train_set.csv', names=['image_id', 'hotel_id', 'image_url', 'image_source', 'upload_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>image_url</th>\n",
       "      <th>image_source</th>\n",
       "      <th>upload_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3485</td>\n",
       "      <td>18187</td>\n",
       "      <td>https://traffickcam.com/images/2016/10/2015090...</td>\n",
       "      <td>traffickcam</td>\n",
       "      <td>9/9/15 17:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3486</td>\n",
       "      <td>18187</td>\n",
       "      <td>https://traffickcam.com/images/2016/10/2015090...</td>\n",
       "      <td>traffickcam</td>\n",
       "      <td>9/9/15 17:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663</td>\n",
       "      <td>73224</td>\n",
       "      <td>https://traffickcam.com/images/2016/10/2015091...</td>\n",
       "      <td>traffickcam</td>\n",
       "      <td>9/17/15 19:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2586939</td>\n",
       "      <td>86350</td>\n",
       "      <td>https://traffickcam.com/images/2017/2/20160125...</td>\n",
       "      <td>traffickcam</td>\n",
       "      <td>1/25/16 19:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2586950</td>\n",
       "      <td>1533</td>\n",
       "      <td>https://traffickcam.com/images/2017/2/20160125...</td>\n",
       "      <td>traffickcam</td>\n",
       "      <td>1/25/16 17:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  hotel_id                                          image_url  \\\n",
       "0      3485     18187  https://traffickcam.com/images/2016/10/2015090...   \n",
       "1      3486     18187  https://traffickcam.com/images/2016/10/2015090...   \n",
       "2      3663     73224  https://traffickcam.com/images/2016/10/2015091...   \n",
       "3   2586939     86350  https://traffickcam.com/images/2017/2/20160125...   \n",
       "4   2586950      1533  https://traffickcam.com/images/2017/2/20160125...   \n",
       "\n",
       "  image_source upload_timestamp  \n",
       "0  traffickcam     9/9/15 17:23  \n",
       "1  traffickcam     9/9/15 17:23  \n",
       "2  traffickcam    9/17/15 19:33  \n",
       "3  traffickcam    1/25/16 19:12  \n",
       "4  traffickcam    1/25/16 17:23  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1124215 entries, 0 to 1124214\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count    Dtype \n",
      "---  ------            --------------    ----- \n",
      " 0   image_id          1124215 non-null  int64 \n",
      " 1   hotel_id          1124215 non-null  int64 \n",
      " 2   image_url         1124215 non-null  object\n",
      " 3   image_source      1124215 non-null  object\n",
      " 4   upload_timestamp  1124215 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 42.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>image_url</th>\n",
       "      <th>image_source</th>\n",
       "      <th>upload_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8381</th>\n",
       "      <td>2631490</td>\n",
       "      <td>37821</td>\n",
       "      <td>https://traffickcam.com/images/2017/8/20160731...</td>\n",
       "      <td>traffickcam</td>\n",
       "      <td>7/31/16 3:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8382</th>\n",
       "      <td>2631492</td>\n",
       "      <td>37821</td>\n",
       "      <td>https://traffickcam.com/images/2017/8/20160731...</td>\n",
       "      <td>traffickcam</td>\n",
       "      <td>7/31/16 3:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668497</th>\n",
       "      <td>6324595</td>\n",
       "      <td>37821</td>\n",
       "      <td>https://i.travelapi.com/hotels/1000000/450000/...</td>\n",
       "      <td>travel_website</td>\n",
       "      <td>2019-12-19 02:30:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668498</th>\n",
       "      <td>6324596</td>\n",
       "      <td>37821</td>\n",
       "      <td>https://i.travelapi.com/hotels/1000000/450000/...</td>\n",
       "      <td>travel_website</td>\n",
       "      <td>2019-12-19 02:30:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668499</th>\n",
       "      <td>6324597</td>\n",
       "      <td>37821</td>\n",
       "      <td>https://i.travelapi.com/hotels/1000000/450000/...</td>\n",
       "      <td>travel_website</td>\n",
       "      <td>2019-12-19 02:30:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668564</th>\n",
       "      <td>6324663</td>\n",
       "      <td>37821</td>\n",
       "      <td>https://i.travelapi.com/hotels/1000000/450000/...</td>\n",
       "      <td>travel_website</td>\n",
       "      <td>2019-12-19 02:30:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668565</th>\n",
       "      <td>6324664</td>\n",
       "      <td>37821</td>\n",
       "      <td>https://i.travelapi.com/hotels/1000000/450000/...</td>\n",
       "      <td>travel_website</td>\n",
       "      <td>2019-12-19 02:30:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668566</th>\n",
       "      <td>6324665</td>\n",
       "      <td>37821</td>\n",
       "      <td>https://i.travelapi.com/hotels/1000000/450000/...</td>\n",
       "      <td>travel_website</td>\n",
       "      <td>2019-12-19 02:30:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668567</th>\n",
       "      <td>6324666</td>\n",
       "      <td>37821</td>\n",
       "      <td>https://i.travelapi.com/hotels/1000000/450000/...</td>\n",
       "      <td>travel_website</td>\n",
       "      <td>2019-12-19 02:30:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668568</th>\n",
       "      <td>6324667</td>\n",
       "      <td>37821</td>\n",
       "      <td>https://i.travelapi.com/hotels/1000000/450000/...</td>\n",
       "      <td>travel_website</td>\n",
       "      <td>2019-12-19 02:30:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_id  hotel_id                                          image_url  \\\n",
       "8381     2631490     37821  https://traffickcam.com/images/2017/8/20160731...   \n",
       "8382     2631492     37821  https://traffickcam.com/images/2017/8/20160731...   \n",
       "668497   6324595     37821  https://i.travelapi.com/hotels/1000000/450000/...   \n",
       "668498   6324596     37821  https://i.travelapi.com/hotels/1000000/450000/...   \n",
       "668499   6324597     37821  https://i.travelapi.com/hotels/1000000/450000/...   \n",
       "...          ...       ...                                                ...   \n",
       "668564   6324663     37821  https://i.travelapi.com/hotels/1000000/450000/...   \n",
       "668565   6324664     37821  https://i.travelapi.com/hotels/1000000/450000/...   \n",
       "668566   6324665     37821  https://i.travelapi.com/hotels/1000000/450000/...   \n",
       "668567   6324666     37821  https://i.travelapi.com/hotels/1000000/450000/...   \n",
       "668568   6324667     37821  https://i.travelapi.com/hotels/1000000/450000/...   \n",
       "\n",
       "          image_source     upload_timestamp  \n",
       "8381       traffickcam         7/31/16 3:58  \n",
       "8382       traffickcam         7/31/16 3:58  \n",
       "668497  travel_website  2019-12-19 02:30:24  \n",
       "668498  travel_website  2019-12-19 02:30:24  \n",
       "668499  travel_website  2019-12-19 02:30:24  \n",
       "...                ...                  ...  \n",
       "668564  travel_website  2019-12-19 02:30:24  \n",
       "668565  travel_website  2019-12-19 02:30:24  \n",
       "668566  travel_website  2019-12-19 02:30:24  \n",
       "668567  travel_website  2019-12-19 02:30:24  \n",
       "668568  travel_website  2019-12-19 02:30:24  \n",
       "\n",
       "[74 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['hotel_id']==37821]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_df = pd.read_csv('input/dataset/hotel_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>Extended Stay America - Fairbanks - Old Airpor...</td>\n",
       "      <td>72</td>\n",
       "      <td>64.83538</td>\n",
       "      <td>-147.82330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392</td>\n",
       "      <td>Hilton Hangzhou Qiandao Lake Resort</td>\n",
       "      <td>3</td>\n",
       "      <td>29.60819</td>\n",
       "      <td>119.07290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>393</td>\n",
       "      <td>Taj Lands End</td>\n",
       "      <td>-1</td>\n",
       "      <td>19.04391</td>\n",
       "      <td>72.81879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>395</td>\n",
       "      <td>Cambridge Suites Hotel Sydney</td>\n",
       "      <td>-1</td>\n",
       "      <td>46.13663</td>\n",
       "      <td>-60.19551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>396</td>\n",
       "      <td>Tamanu Beach</td>\n",
       "      <td>14</td>\n",
       "      <td>-18.84213</td>\n",
       "      <td>-159.78794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hotel_id                                         hotel_name  chain_id  \\\n",
       "0       391  Extended Stay America - Fairbanks - Old Airpor...        72   \n",
       "1       392                Hilton Hangzhou Qiandao Lake Resort         3   \n",
       "2       393                                      Taj Lands End        -1   \n",
       "3       395                      Cambridge Suites Hotel Sydney        -1   \n",
       "4       396                                       Tamanu Beach        14   \n",
       "\n",
       "   latitude  longitude  \n",
       "0  64.83538 -147.82330  \n",
       "1  29.60819  119.07290  \n",
       "2  19.04391   72.81879  \n",
       "3  46.13663  -60.19551  \n",
       "4 -18.84213 -159.78794  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   hotel_id    50000 non-null  int64  \n",
      " 1   hotel_name  50000 non-null  object \n",
      " 2   chain_id    50000 non-null  int64  \n",
      " 3   latitude    50000 non-null  float64\n",
      " 4   longitude   50000 non-null  float64\n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "hotel_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13735</th>\n",
       "      <td>18934</td>\n",
       "      <td>HYATT house Raleigh Durham Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>35.85567</td>\n",
       "      <td>-78.84269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hotel_id                          hotel_name  chain_id  latitude  \\\n",
       "13735     18934  HYATT house Raleigh Durham Airport         1  35.85567   \n",
       "\n",
       "       longitude  \n",
       "13735  -78.84269  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_df[hotel_df['hotel_id']==18934]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_df = pd.read_csv('input/dataset/chain_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chain_id</th>\n",
       "      <th>chain_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Best Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Hyatt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Marriott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Hilton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>Motel 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>Sheraton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>Homewood Suites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>SpringHill Suites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>Comfort Suites</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    chain_id         chain_name\n",
       "0         -1            unknown\n",
       "1          0       Best Western\n",
       "2          1              Hyatt\n",
       "3          2           Marriott\n",
       "4          3             Hilton\n",
       "..       ...                ...\n",
       "75        75            Motel 6\n",
       "76        76           Sheraton\n",
       "77        77    Homewood Suites\n",
       "78        78  SpringHill Suites\n",
       "79        79     Comfort Suites\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_df.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93 entries, 0 to 92\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   chain_id    93 non-null     int64 \n",
      " 1   chain_name  93 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "chain_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Mini Model\n",
    "Testing to see if I am able to run a model with a subset of the Train data. The train2 and test2 datasets are extracted from the original Train dataset from chains 1, 22, and 39."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 155 images belonging to 3 classes.\n",
      "Found 70 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width = 640\n",
    "img_height = 360\n",
    "batch_size =10\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling (we do not want to modify the testing data)\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\n",
    "# The generator object. \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './images/train2',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    './images/test2',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 640, 360\n",
    "\n",
    "nb_train_samples = 155\n",
    "nb_validation_samples = 70\n",
    "epochs = 5\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(640, 360, 3)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(3,\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=keras.regularizers.l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 56s 20s/step - loss: 2.2423 - accuracy: 0.3682 - val_loss: 3.4295 - val_accuracy: 0.2000\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 51s 13s/step - loss: 2.0194 - accuracy: 0.4750 - val_loss: 1.0024 - val_accuracy: 0.6462\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 46s 13s/step - loss: 0.9922 - accuracy: 0.5267 - val_loss: 1.3985 - val_accuracy: 0.2154\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 51s 11s/step - loss: 1.2320 - accuracy: 0.3953 - val_loss: 1.0755 - val_accuracy: 0.5385\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 47s 12s/step - loss: 1.0490 - accuracy: 0.4939 - val_loss: 0.9887 - val_accuracy: 0.6615\n"
     ]
    }
   ],
   "source": [
    "# m = model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=nb_train_samples // batch_size,\n",
    "#         epochs=epochs,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting 1M Train Dataset into Train and Test\n",
    "Original Test dataset of 17k images have occlusions that the original Train dataset does not. To make things easier in the preliminary stages of this project, we will only train and test on the unoccluded Train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for folder in train\n",
    "    # loop through each chain\n",
    "    # loop through each location in the chain folder\n",
    "        #create test chain folder for each train chain folder\n",
    "        # if traffic cam folder exists:\n",
    "        # loop through trafficcam folder\n",
    "            #count length of folder \n",
    "            # take random 20 percent of images\n",
    "            # (take 20 (.2 * len of folder) random numbers from \n",
    "            #1-100 (len of folder) out of 100 images)\n",
    "            #NOTE: also grab a list of the image names\n",
    "        # if travel folder exists:\n",
    "        # loop through travel folder\n",
    "            \n",
    "# creating a fxn \n",
    "\n",
    "#count length of folder \n",
    "            # take random 20 percent of images\n",
    "            # (take 20 (.2 * len of folder) random numbers from \n",
    "            #1-100 (len of folder) out of 100 images)\n",
    "            #NOTE: also grab a list of the image names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1069', '1855', '4729', '2886', '23278', '36598', '11188', '2288', '8574', '5865', '10892', '5059', '39372', '26994', '2618', '763', '8110', '6617', '3365', '23849', '10859', '37647', '21722', '4140', '89643', '4372', '6425', '3157', '116569', '4716', '6041', '9009', '35574', '98355', '3701', '10401', '4524', '86861', '11715', '32597', '22705', '7167', '35580', '2627', '11527', '2243', '27421', '10091', '75406', '11143', '5066', '46278', '8117', '39375', '43538', '113681', '85270', '11349', '5896', '10861', '106195', '9667', '3953', '2881', '204289', '8587', '38405', '203890', '6845', '7997', '127216', '206986', '32769', '7399', '790', '33026', '5253', '4381', '34203', '2076', '78910', '7736', '2244', '10096', '14436', '7352', '2620', '28836', '1899', '5405', '11712', '25527', '569', '8128', '3706', '12351', '1051', '4523', '1263', '4711', '9832', '27284', '61491', '111921', '121788', '1435', '4147', '5068', '52824', '44941', '2843', '19576', '7955', '8121', '560', '6887', '6289', '1890', '128268', '21946', '98955', '1058', '6619', '8783', '4972', '45269', '45867', '40529', '76877', '3159', '1093', '11516', '21383', '7364', '7156', '11724', '2040', '3192', '11340', '90599', '37682', '2272', '2888', '4343', '5291', '4171', '105719', '23044', '7390', '6242', '3730', '3502', '10602', '142688', '3962', '17249', '9656', '23840', '4975', '45438', '144781', '87172', '1897', '1299', '72840', '2844', '9490', '115775', '23088', '3398', '8770', '5853', '3505', '7999', '10605', '15377', '35542', '47162', '95824', '1404', '4176', '3161', '1636', '10261', '5296', '11175', '123826', '7707', '16350', '107881', '900', '27625', '2047', '3195', '11347', '44979', '88753', '8925', '6083', '8119', '85428', '197140', '5606', '15383', '11511', '7363', '98397', '2611', '3763', '1808', '4546', '1034', '88397', '10651', '3551', '85488', '2483', '9857', '1662', '3135', '6447', '26565', '5236', '34266', '2221', '7753', '20666', '5838', '3797', '2645', '10497', '11545', '118465', '27215', '7105', '8971', '4921', '7798', '9430', '92858', '3936', '8186', '9054', '79434', '9868', '5699', '1239', '4579', '9266', '79606', '2448', '533', '58929', '8340', '93714', '78720', '30893', '74589', '5807', '8724', '35985', '18093', '16935', '5655', '4787', '11770', '2470', '9098', '7102', '739', '28068', '2226', '27444', '50516', '6686', '7754', '22136', '1691', '96408', '2828', '55090', '3300', '4125', '4317', '14692', '41490', '1665', '10232', '54370', '6440', '89242', '4773', '11784', '32506', '22794', '6024', '3764', '10464', '2817', '82205', '8723', '706', '46028', '8175', '7901', '8949', '68787', '15915', '11589', '90162', '2689', '3569', '8181', '107673', '79433', '10669', '9437', '998', '10803', '1468', '5809', '1495', '27472', '7762', '8518', '11322', '3594', '7908', '8940', '5663', '11746', '10694', '4583', '5451', '11574', '2674', '7306', '30267', '8188', '1237', '4577', '11580', '1005', '2680', '89422', '15544', '45234', '10036', '6644', '3938', '6476', '10204', '49056', '10499', '502', '8143', '7937', '94356', '1698', '8527', '2821', '8715', '83315', '19184', '9401', '3907', '79061', '9633', '42812', '10835', '10009', '4910', '8385', '1208', '9065', '9859', '6471', '4326', '10203', '1654', '3331', '12766', '398', '4570', '2687', '3755', '6829', '204681', '3567', '6015', '4742', '5690', '5456', '2673', '205595', '78729', '2441', '9895', '7133', '7557', '15785', '5032', '21782', '2217', '22107', '7765', '3558', '6218', '1801', '23822', '111171', '10832', '1459', '90705', '9406', '3900', '8712', '33278', '8520', '2826', '737', '27812', '5469', '1298', '39177', '7953', '78775', '123440', '8771', '3399', '7739', '11977', '4980', '87517', '8543', '3997', '3963', '592', '6875', '6049', '3709', '18664', '9233', '51039', '79653', '105344', '1862', '2046', '5263', '2274', '5435', '11510', '7150', '8924', '6082', '40180', '4513', '100609', '3736', '40948', '12537', '73500', '36590', '4345', '5899', '2280', '30455', '6620', '35127', '1059', '595', '10258', '3964', '9650', '4973', '25977', '58523', '24099', '8544', '34805', '69056', '57759', '8312', '2628', '1891', '11528', '7168', '4170', '10869', '11187', '10055', '1402', '6627', '3167', '6415', '76849', '9039', '9805', '4726', '4514', '108463', '2425', '5600', '1092', '108497', '2617', '88567', '28459', '7701', '906', '7533', '52026', '10293', '9454', '28696', '2880', '32902', '122301', '95017', '4179', '5897', '4945', '85285', '9666', '10438', '9202', '791', '3738', '6844', '765', '49003', '557', '7962', '80155', '11348', '69060', '8740', '3535', '30000', '17622', '23417', '10407', '3363', '29549', '6611', '1434', '10251', '11383', '2083', '3397', '11979', '10097', '33215', '101974', '4380', '2077', '7505', '11713', '2413', '8915', '2621', '5404', '11521', '5058', '5864', '550', '8111', '40189', '38093', '11519', '85612', '8323', '48310', '73951', '6843', '90334', '796', '133610', '5890', '11189', '2289', '82295', '10269', '2626', '5403', '11526', '130862', '33676', '66646', '11714', '58975', '2414', '7166', '8912', '24097', '7502', '937', '76282', '3390', '8778', '2242', '4989', '4373', '3156', '31783', '5093', '4141', '4525', '38864', '10632', '1265', '9834', '8946', '2440', '3592', '130238', '39318', '75037', '11572', '5457', '7300', '2672', '709', '5033', '2216', '6484', '2818', '20463', '5201', '4929', '3330', '399', '79058', '6014', '16591', '6828', '10454', '6226', '22596', '2686', '3754', '203836', '117041', '112533', '2827', '8521', '27679', '77109', '8713', '2229', '4788', '8979', '7931', '6817', '9063', '3559', '4318', '3901', '9407', '10833', '1004', '9269', '3753', '6013', '3561', '1236', '4744', '19986', '73565', '207466', '74572', '1460', '100208', '4112', '3337', '93971', '7551', '16106', '6483', '2023', '5206', '1494', '82803', '4582', '37285', '7307', '11747', '3308', '4911', '24833', '3906', '9400', '116504', '40912', '12935', '87324', '206927', '2478', '9090', '503', '731', '91625', '44922', '1699', '8526', '117887', '4316', '9409', '35948', '1456', '10001', '4124', '17640', '3765', '10465', '5492', '1200', '4772', '51267', '6025', '26335', '2485', '8379', '738', '11543', '5466', '4786', '7103', '8977', '11315', '1690', '44117', '952', '7567', '204221', '8180', '3568', '6826', '9260', '59663', '10802', '397', '999', '79056', '3930', '9436', '13489', '4329', '2218', '8722', '8948', '535', '20009', '5459', '707', '9294', '7752', '5005', '11312', '1697', '5237', '16137', '25543', '5653', '7104', '7938', '7336', '16761', '22554', '3796', '2644', '10496', '5461', '14036', '1207', '11782', '21117', '8984', '6022', '2482', '98336', '3762', '10462', '4547', '1663', '4311', '6446', '3908', '7309', '700', '27019', '107681', '8173', '7907', '532', '2449', '11749', '75668', '55861', '8725', '3937', '9431', '10039', '141636', '24668', '4578', '83573', '9267', '8187', '102307', '9055', '5698', '1944', '12278', '81164', '3079', '18928', '76957', '91792', '2399', '8465', '5148', '10983', '9785', '126828', '11409', '672', '91302', '10948', '5183', '62554', '10346', '1711', '2194', '6534', '14382', '10722', '1381', '8802', '2736', '5513', '11436', '3280', '7620', '4899', '4297', '5345', '75725', '11260', '2160', '80419', '8006', '5719', '10984', '5973', '8650', '28540', '8462', '2964', '11258', '10970', '4855', '8496', '79918', '2990', '3842', '9120', '29230', '6168', '681', '4290', '20520', '11267', '2167', '820', '3889', '7415', '3287', '5170', '10187', '26081', '46164', '7243', '1988', '5726', '197060', '11603', '2503', '13968', '6365', '4432', '1140', '75180', '4600', '21062', '1372', '10725', '10341', '2193', '12416', '3273', '16284', '4056', '5184', '10173', '145321', '5179', '4897', '4299', '3880', '8030', '2738', '643', '1981', '91101', '18541', '485', '6962', '9324', '1149', '9740', '28582', '6708', '59515', '40438', '3874', '131891', '7275', '6195', '16410', '7047', '3083', '2151', '7423', '11251', '2363', '7611', '16246', '3077', '6505', '2999', '4252', '4060', '1512', '42162', '2397', '15053', '4404', '89135', '1176', '3621', '9129', '3413', '9915', '23703', '4636', '67641', '1344', '10713', '17956', '3873', '81536', '9747', '81704', '.DS_Store', '9323', '51915', '26847', '15259', '482', '8205', '9581', '2169', '22279', '2955', '10189', '45516', '1171', '3626', '4067', '5989', '9778', '2390', '4255', '10370', '40400', '5141', '25251', '19209', '2364', '2156', '811', '5373', '2532', '449', '7040', '5717', '1185', '6300', '3672', '91199', '5585', '1317', '10740', '47215', '3440', '97438', '7484', '6556', '3024', '12473', '79942', '6764', '3216', '10116', '1541', '1787', '5327', '845', '85935', '8438', '2102', '6790', '2330', '5929', '7226', '43473', '2754', '11454', '4691', '5743', '7014', '31261', '10129', '4830', '10915', '23905', '9979', '6931', '9145', '1328', '1926', '422', '11659', '48898', '8251', '109861', '22823', '8635', '16824', '38585', '82313', '11661', '39837', '5744', '7013', '8867', '50063', '7221', '46562', '6797', '26487', '18986', '23101', '3211', '4034', '10323', '89737', '4206', '7483', '6551', '205217', '6135', '2595', '6909', '2906', '5911', '8632', '14922', '5549', '8858', '425', '83464', '2798', '8090', '889', '9526', '205228', '32870', '4239', '1579', '29404', '92340', '5124', '12684', '2133', '11233', '3485', '2557', '75312', '11657', '20110', '4492', '2765', '205483', '9977', '28389', '205645', '5786', '32613', '4466', '2791', '1570', '10127', '76335', '880', '4230', '110525', '23598', '3688', '8260', '41924', '2568', '413', '203921', '126611', '8436', '8604', '39654', '3816', '34983', '8294', '24749', '37950', '6900', '1745', '10312', '4839', '56735', '1577', '4005', '113708', '23130', '34187', '7680', '3220', '1113', '4461', '90841', '35431', '6336', '6104', '9970', '11462', '50052', '619', '121854', '9984', '2550', '5775', '873', '16011', '7446', '2134', '11234', '33164', '5123', '140609', '10749', '9173', '6309', '8293', '15835', '9725', '87491', '4208', '3811', '2339', '8603', '79183', '7479', '27769', '24588', '4698', '41923', '8869', '7821', '9187', '626', '21099', '477', '8036', '12089', '645', '1987', '10188', '5943', '11268', '2954', '8452', '4865', '3872', '9574', '86376', '483', '18775', '3618', '19806', '810', '2157', '77045', '5372', '205083', '11401', '91138', '131897', '91904', '5524', '7273', '2701', '6193', '7041', '448', '8009', '36011', '10527', '6355', '7287', '6167', '73075', '9913', '1342', '3071', '1726', '5386', '10143', '4066', '6731', '12614', '3243', '2391', '27993', '46198', '47876', '15851', '1148', '1974', '4608', '9117', '19492', '10349', '3875', '9573', '3881', '828', '8667', '8203', '33769', '101606', '110774', '470', '7845', '10144', '11096', '4061', '6736', '18927', '1721', '5381', '6160', '1345', '17705', '7280', '689', '6194', '7046', '2534', '11634', '5711', '11406', '1183', '20341', '5523', '2706', '11062', '5147', '8658', '7422', '817', '3082', '43277', '5375', '3843', '17966', '8497', '5388', '5986', '81734', '85394', '7289', '3629', '6169', '7887', '87053', '15893', '78655', '43428', '7873', '8007', '446', '2159', '41529', '11259', '206608', '10985', '7619', '24511', '4601', '9922', '6156', '47271', '10516', '30575', '1525', '10172', '11292', '10340', '6532', '109006', '3286', '10186', '11266', '4291', '3888', '2166', '43241', '5727', '88216', '2502', '479', '6390', '33760', '1989', '5975', '5149', '78236', '9784', '8656', '819', '2962', '78460', '7874', '441', '11408', '8232', '2708', '7880', '4639', '39296', '74857', '5981', '6738', '9770', '2996', '3844', '3078', '6397', '2737', '11437', '1380', '11605', '7077', '46350', '2505', '826', '9589', '28579', '2353', '8669', '39639', '15635', '26625', '30572', '3275', '10175', '10949', '89561', '6363', '10511', '1146', '15063', '38149', '4606', '3423', '2551', '27333', '10783', '4494', '618', '2763', '72303', '5122', '11007', '75542', '2307', '7675', '77027', '872', '5310', '11235', '4004', '15453', '4838', '1576', '9529', '3013', '10313', '6939', '6105', '4652', '74232', '4460', '30142', '8430', '6798', '11804', '5921', '627', '36870', '9186', '415', '1911', '74803', '10748', '6906', '89738', '9516', '3810', '4807', '1115', '11490', '3642', '8098', '6102', '4655', '3014', '881', '4231', '2132', '8408', '6592', '85905', '7440', '11232', '5125', '1585', '2300', '47487', '7672', '4493', '11464', '77676', '17793', '7024', '5773', '10784', '11656', '9723', '3817', '6901', '9175', '81136', '8295', '81304', '4458', '91350', '8053', '9181', '44659', '102485', '13768', '94074', '5328', '2931', '1775', '10322', '3022', '6550', '139437', '4035', '10574', '15234', '11694', '1311', '6134', '8892', '35633', '629', '3680', '7220', '88046', '10580', '4697', '2560', '31267', '34715', '17597', '7012', '5321', '1781', '203929', '2104', '2938', '2336', '7644', '11036', '91392', '45749', '208360', '2799', '76759', '6339', '9715', '4238', '2309', '424', '5548', '57278', '9385', '8257', '2331', '11031', '88617', '36421', '117159', '12486', '99557', '7471', '844', '18980', '11667', '2755', '5570', '10741', '12016', '6301', '36283', '4456', '5584', '1124', '3217', '4032', '1540', '10117', '1772', '32075', '3025', '205211', '6557', '39200', '423', '7816', '5319', '204906', '80677', '3826', '119834', '10128', '100317', '9712', '74835', '9144', '6930', '81107', '16489', '21805', '16209', '136491', '859', '95387', '8040', '19417', '401', '11448', '6912', '8888', '4679', '1139', '10936', '3038', '3804', '7498', '2777', '27115', '7205', '5552', '5760', '10797', '8843', '46310', '33171', '79995', '6581', '866', '2313', '7661', '39679', '4222', '892', '6575', '111876', '3235', '4010', '12206', '3651', '102039', '4474', '10551', '5794', '10763', '6111', '9505', '3803', '76911', '83211', '10931', '4814', '9737', '10569', '79733', '73209', '6129', '11689', '14901', '8047', '5758', '142725', '19074', '87477', '5932', '7659', '4641', '76576', '16493', '9962', '6116', '9708', '6740', '113528', '4225', '24909', '10300', '13585', '42327', '2314', '204120', '16231', '7666', '5131', '11014', '36404', '5303', '2126', '78840', '26696', '7454', '5767', '11642', '3490', '8078', '2542', '439', '9996', '2770', '5555', '9365', '1934', '74826', '86103', '4648', '8085', '81570', '9701', '6749', '8415', '2913', '8627', '1598', '5904', '8243', '78623', '203768', '66719', '430', '28361', '66184', '10104', '3204', '42123', '6776', '6544', '1761', '9168', '2580', '3452', '9954', '71765', '11680', '10752', '1305', '4445', '15012', '5597', '1137', '30167', '8288', '3660', '6312', '2574', '71791', '37184', '63066', '3694', '5107', '11022', '16207', '7650', '6782', '2110', '145531', '437', '85775', '9396', '13329', '605', '8244', '4489', '8620', '7668', '5903', '11228', '6588', '29416', '1759', '87680', '84005', '92160', '9534', '6924', '9362', '132038', '33147', '6785', '11441', '10593', '2741', '3693', '50071', '17584', '41103', '197010', '24594', '6315', '3455', '9953', '8881', '4670', '15227', '3031', '7491', '6543', '17114', '24938', '83811', '50441', '9799', '11071', '4086', '5366', '124109', '2143', '17988', '75362', '39871', '6187', '7869', '11415', '32697', '1190', '10701', '9907', '6341', '6725', '3257', '2385', '1500', '11085', '4072', '10365', '67237', '4240', '6517', '26607', '123545', '18795', '50826', '2518', '6984', '11618', '124136', '80405', '202883', '82160', '8674', '9560', '25881', '10168', '4871', '8680', '3268', '4429', '1967', '9938', '497', '1369', '1735', '10362', '116804', '5395', '6510', '3062', '6722', '3250', '10150', '4849', '21617', '7294', '10534', '1163', '4411', '86954', '669', '5537', '67492', '11620', '5705', '46375', '7436', '803', '2978', '7604', '2376', '11076', '10998', '4081', '7099', '9103', '10739', '1960', '6379', '79751', '1538', '4876', '10953', '54811', '30568', '3861', '4278', '5950', '11049', '39247', '16608', '656', '4427', '35477', '23512', '3602', '9338', '35645', '34797', '1367', '10730', '3868', '2186', '3054', '10354', '10166', '5191', '70083', '6714', '835', '2172', '4285', '5357', '10192', '5165', '7632', '204174', '11424', '7064', '1393', '70621', '79303', '3259', '4840', '71952', '10965', '9551', '8483', '86353', '1956', '4418', '39043', '112001', '6189', '452', '2529', '7269', '39271', '8645', '5966', '7063', '2511', '1394', '5734', '5506', '6383', '106439', '658', '2723', '10195', '3295', '832', '7407', '11275', '119889', '4282', '14707', '33919', '1536', '4044', '3053', '10353', '1704', '7097', '9931', '6145', '10737', '1360', '37115', '4612', '1152', '3098', '23986', '8642', '22854', '5961', '63458', '80265', '667', '1199', '129049', '5539', '7860', '6348', '693', '4249', '9764', '1509', '100130', '12458', '9535', '47468', '9707', '10901', '9363', '3659', '83477', '4488', '39027', '28367', '7803', '124163', '2129', '8621', '64083', '6126', '2586', '3454', '11686', '4671', '25681', '1131', '4443', '1555', '20797', '4027', '6770', '84209', '3202', '9738', '125846', '1767', '6784', '851', '1793', '11216', '5333', '8874', '2572', '409', '8048', '4685', '20135', '34535', '3692', '80665', '8626', '86592', '869', '2912', '8414', '36854', '10798', '7038', '431', '3498', '8070', '7804', '603', '8242', '4649', '17549', '12807', '9156', '9364', '144623', '1935', '9700', '92354', '10906', '38562', '10308', '3834', '73468', '11447', '10595', '5562', '50245', '8873', '7007', '4682', '37185', '5750', '7463', '856', '43236', '95388', '11023', '8619', '7497', '1760', '10337', '4020', '10561', '4444', '3661', '6121', '9955', '4676', '96160', '8046', '69766', '19623', '7658', '2924', '2118', '8422', '86550', '10930', '3802', '18153', '79958', '95375', '6914', '11688', '3668', '9352', '11227', '101018', '6587', '7455', '2127', '11015', '7203', '11471', '4486', '5766', '438', '3657', '2785', '1100', '11485', '1332', '10765', '56170', '3465', '90638', '10301', '45103', '894', '99587', '3001', '98455', '6741', '7693', '10133', '74816', '1904', '28197', '48072', '8889', '6913', '73801', '4678', '3805', '9503', '113723', '143053', '58684', '10937', '6779', '2923', '5934', '11811', '5108', '8617', '11449', '8041', '9193', '6746', '7694', '86568', '10134', '4011', '21673', '1751', '6574', '893', '46781', '3006', '1335', '9964', '74015', '10550', '11482', '4475', '10796', '11644', '7036', '8842', '2544', '22466', '7204', '4481', '2312', '8628', '11220', '7452', '2120', '2180', '3052', '133941', '12405', '11280', '1705', '10352', '4045', '5197', '4879', '10160', '3260', '139675', '10504', '75193', '26066', '6376', '6978', '7096', '17513', '4613', '14150', '117778', '2722', '5735', '11610', '77066', '2948', '20533', '11274', '87628', '10194', '77254', '7634', '10709', '7895', '18564', '6947', '9133', '9301', '1508', '4248', '8485', '3851', '103511', '8643', '140676', '206428', '2977', '7439', '8015', '8829', '35688', '49100', '666', '5538', '135417', '15881', '5164', '2341', '3293', '2173', '8449', '7401', '4284', '5356', '14701', '11273', '7065', '8811', '75352', '2725', '7257', '6143', '4614', '197080', '4426', '3603', '76711', '4042', '30560', '3267', '54819', '3055', '3869', '22297', '21412', '4270', '56540', '10355', '1702', '41964', '7866', '96134', '5369', '48683', '2970', '138559', '16069', '85375', '10990', '8482', '2984', '6518', '3856', '9762', '77298', '10964', '10158', '39284', '87280', '9908', '5704', '2521', '2377', '5152', '10999', '11077', '3097', '2145', '2979', '3251', '22093', '17374', '128504', '5394', '10363', '84068', '10707', '80890', '6175', '7295', '4410', '119288', '11048', '8672', '2348', '22058', '5509', '465', '8818', '91327', '1961', '92764', '9330', '6378', '491', '6976', '27388', '7098', '9566', '3860', '10952', '1539', '4877', '22890', '8686', '60219', '9308', '3632', '90837', '4417', '1165', '75397', '1357', '81945', '92936', '6516', '26434', '3256', '2384', '6724', '4073', '45354', '10156', '5367', '3090', '2142', '805', '2370', '50440', '123923', '11070', '13343', '31013', '44616', '5531', '11414', '1191', '118534', '5703', '2526', '7868', '6186', '10955', '4870', '23945', '48474', '9753', '9561', '81522', '496', '40873', '4428', '15843', '9337', '6985', '11619', '130153', '8211', '7259', '80252', '8447', '3893', '5358', '202882', '5824', '8707', '16916', '7119', '8151', '206934', '94512', '48196', '2659', '8999', '48350', '69685', '4768', '1028', '208254', '1814', '3915', '11566', '4591', '5443', '44556', '20013', '9880', '19539', '7542', '977', '2202', '5027', '10216', '1641', '45828', '79870', '92078', '7784', '73744', '18249', '10818', '4101', '2692', '3740', '207223', '4565', '1225', '5685', '6000', '4905', '97156', '6804', '102322', '2498', '88976', '121968', '9084', '5649', '2008', '32525', '101598', '9873', '16582', '6235', '2695', '3747', '86827', '7783', '6651', '10023', '4106', '4334', '6463', '7777', '13652', '1480', '5020', '41447', '7545', '970', '14221', '528', '2453', '8169', '3581', '5444', '9274', '4759', '8194', '205748', '9046', '45826', '18849', '107202', '3924', '3118', '6658', '10816', '979', '8504', '19361', '12789', '5815', '5029', '9280', '713', '7128', '3588', '8160', '7914', '521', '10015', '73775', '3315', '107833', '6455', '7587', '35352', '54365', '10227', '51273', '10471', '24644', '74134', '1026', '4554', '6203', '12326', '42690', '5640', '5472', '7325', '3785', '11133', '6693', '7741', '50731', '7573', '12584', '11301', '5678', '7913', '714', '89895', '4598', '2805', '111394', '205925', '4108', '6835', '3749', '1822', '83567', '7574', '1683', '203017', '5223', '11134', '95891', '11908', '6694', '23492', '3782', '63342', '11762', '5647', '10476', '4553', '21331', '73316', '6036', '73540', '1445', '10012', '23002', '3312', '2260', '7712', '5879', '14620', '5277', '206531', '2052', '8568', '915', '5613', '88322', '8930', '7144', '2604', '13253', '7376', '11504', '17435', '42405', '3722', '2294', '3346', '67114', '82886', '1623', '6406', '66469', '7947', '572', '9485', '3983', '5248', '5846', '8765', '9471', '6439', '3977', '11399', '10845', '10079', '35930', '22987', '1876', '4538', '116747', '586', '9015', '1278', '36583', '5284', '10273', '24046', '1624', '30674', '2293', '26523', '6633', '10041', '4500', '1072', '4732', '1240', '98143', '6859', '23607', '9811', '17432', '6065', '7371', '14071', '70706', '91208', '7143', '11355', '3187', '141488', '16170', '13630', '2267', '10889', '3528', '9012', '73974', '581', '7188', '38270', '9220', '83150', '10842', '5089', '4967', '1429', '91495', '8796', '9476', '76862', '4993', '11158', '9482', '8550', '2856', '80513', '8134', '6892', '575', '16719', '1044', '3713', '7181', '3979', '5080', '4152', '1420', '3377', '8559', '2063', '13434', '7511', '16146', '4394', '5074', '5848', '2251', '7723', '20272', '5410', '40397', '2635', '7347', '7949', '8901', '5622', '1282', '3348', '118288', '10048', '5883', '9818', '90929', '2438', '77718', '96216', '10880', '4199', '91665', '2400', '1285', '5417', '13265', '3384', '7724', '2064', '22374', '923', '2858', '14616', '5241', '10070', '4969', '3370', '3142', '2090', '18813', '119150', '4367', '1615', '6868', '7186', '4703', '3714', '6266', '114684', '16942', '3189', '103633', '7529', '2867', '8753', '2269', '22179', '5870', '544', '8105', '7971', '8939', '1840', '87397', '9023', '7985', '4358', '98529', '18010', '121597', '4956', '119930', '9424', '84115', '9616', '4935', '3748', '1823', '9040', '6008', '5679', '87300', '7912', '15798', '91601', '16921', '8502', '2804', '19367', '3545', '18428', '8991', '10645', '67525', '1020', '6205', '10013', '38679', '3313', '6453', '7581', '4304', '1676', '7747', '7575', '88713', '8159', '518', '4794', '5474', '3783', '30084', '5028', '1488', '8505', '2803', '520', '8353', '19704', '11569', '6833', '125537', '51843', '18622', '9275', '6659', '119339', '10219', '3119', '5473', '16773', '7324', '34611', '39932', '2000', '61077', '36522', '20447', '1685', '2232', '6692', '7740', '78992', '18877', '7586', '128673', '1443', '10014', '3314', '3770', '29966', '26112', '516', '7923', '8157', '5648', '8365', '5822', '7749', '28411', '8533', '11309', '4138', '74558', '3913', '1678', '2499', '6039', '11799', '36389', '9243', '51875', '25103', '2036', '971', '2204', '7776', '1481', '2660', '9288', '7312', '4597', '14012', '5445', '25755', '5677', '112946', '206131', '529', '80917', '76492', '3580', '8168', '7120', '120884', '2694', '3746', '6234', '32716', '10446', '4751', '5683', '42653', '9872', '45012', '1647', '3110', '4107', '8396', '9412', '3914', '7588', '10826', '4903', '8534', '78968', '949', '5825', '2658', '8362', '511', '9082', '7924', '3325', '10025', '1472', '3117', '5684', '3573', '138888', '2693', '3741', '4564', '10441', '58108', '89293', '5670', '11755', '3587', '9881', '7315', '4590', '5442', '7771', '21796', '101932', '5214', '88725', '6491', '3143', '2091', '10243', '4154', '81608', '6267', '13290', '3715', '9821', '34680', '32577', '10627', '11533', '5416', '7341', '99267', '8309', '8907', '2401', '116589', '5624', '95698', '16140', '64560', '2065', '11365', '4392', '83997', '5072', '7725', '34022', '23095', '3385', '10618', '105155', '6856', '7984', '37208', '140793', '95839', '4957', '3940', '2892', '11168', '10886', '3188', '8938', '545', '7970', '34479', '8336', '1089', '5849', '3382', '2250', '7510', '8558', '5247', '8900', '2406', '5623', '11534', '7346', '50938', '26184', '589', '1277', '4705', '15352', '10412', '1045', '4537', '1879', '9228', '3712', '1421', '5081', '141679', '3978', '3144', '144139', '67316', '770', '109559', '11739', '117463', '6099', '80140', '8103', '5278', '25954', '2861', '8567', '115562', '43148', '5876', '4198', '91690', '207418', '76855', '3947', '6409', '26719', '141646', '9673', '10875', '98379', '37801', '6851', '7983', '12148', '8936', '2430', '8338', '779', '11502', '5427', '11166', '33236', '10888', '82048', '11354', '10286', '5271', '7526', '2054', '6632', '2292', '11192', '1417', '203283', '10272', '4357', '9448', '26710', '1241', '10616', '62236', '4733', '6064', '6858', '51014', '6256', '3724', '4501', '3985', '80512', '7519', '85060', '132376', '5418', '746', '7941', '6893', '1870', '15169', '7189', '6867', '9477', '1428', '10843', '28487', '30478', '8797', '6251', '3723', '1074', '4734', '6063', '3511', '1622', '4350', '5282', '6407', '3949', '3175', '6635', '2295', '10047', '11353', '5276', '914', '7521', '2053', '7713', '27403', '2261', '11161', '4196', '7377', '13252', '33655', '5612', '26387', '7979', '204603', '2437', '10078', '8790', '2098', '16981', '90773', '11398', '32926', '37468', '6860', '9226', '573', '6894', '741', '112776', '2850', '5249', '34434', '5464', '10493', '4784', '11317', '12592', '16132', '145856', '2225', '6685', '11919', '1666', '3131', '78985', '6443', '47764', '4126', '10003', '1454', '3767', '6215', '5490', '10467', '1030', '10655', '44318', '8720', '2028', '6488', '2814', '80135', '20837', '4589', '28868', '705', '28054', '30897', '6018', '1833', '9262', '107442', '67952', '4925', '9606', '395', '9434', '4777', '1205', '9854', '6020', '4545', '3304', '6676', '10838', '4121', '1453', '4313', '206587', '1661', '3136', '18867', '8718', '2222', '7750', '5007', '36700', '11122', '75467', '5235', '19941', '7562', '85827', '11774', '2474', '3794', '7334', '5463', '11546', '10494', '3109', '9433', '24800', '10209', '1834', '1008', '64388', '84566', '11579', '2679', '8343', '7905', '7139', '10699', '8515', '16936', '92093', '2813', '79295', '4117', '3332', '6640', '995', '10200', '9862', '5693', '4741', '10664', '4573', '74113', '1001', '10456', '2442', '539', '9896', '13829', '10690', '20839', '11742', '2670', '9298', '11114', '1491', '99640', '2214', '7766', '2026', '961', '35381', '5203', '11326', '8381', '9253', '1802', '10469', '11789', '2489', '9061', '1668', '19180', '3903', '47558', '17228', '4128', '4914', '11319', '2825', '85220', '8711', '108897', '5658', '88369', '80938', '7933', '8147', '506', '966', '34254', '2213', '106935', '8729', '43908', '7761', '5452', '14005', '11577', '48984', '2445', '9891', '4574', '118691', '6223', '3563', '6011', '5694', '1234', '24456', '992', '139512', '4322', '1650', '4110', '10809', '3335', '7934', '9092', '733', '22558', '8716', '5009', '5835', '69204', '2822', '48517', '84301', '4913', '24831', '84133', '3904', '7598', '6812', '205768', '8988', '8386', '5499', '75059', '5439', '82432', '767', '12997', '8928', '87372', '52449', '78110', '8570', '10298', '11178', '10896', '2882', '9456', '8584', '4349', '4947', '1851', '81243', '9200', '92466', '10608', '7735', '2247', '11147', '94930', '4382', '932', '2075', '1294', '5634', '52644', '10637', '1260', '38861', '7197', '9831', '6045', '3537', '4520', '73701', '6613', '16396', '3361', '1436', '10061', '5096', '10253', '1604', '4376', '2081', '9469', '7993', '24608', '1856', '17618', '9207', '10059', '5892', '51469', '9663', '2885', '5866', '4188', '9697', '2871', '49650', '5268', '6089', '8113', '552', '11729', '21980', '86608', '202979', '6426', '3968', '2086', '35113', '12731', '26504', '76274', '10066', '4143', '6270', '12355', '10402', '24637', '1055', '32752', '7190', '6042', '3530', '6284', '5401', '1293', '7958', '4385', '5257', '8548', '7732', '2240', '10092', '20607', '9655', '10639', '14299', '73159', '23629', '51209', '590', '19586', '6279', '9231', '76619', '207268', '6883', '7951', '103879', '756', '2249', '11149', '44945', '202984', '100096', '10434', '4511', '3734', '9800', '6848', '72888', '1251', '10606', '6410', '9458', '1635', '11182', '7536', '903', '3196', '5261', '11176', '4181', '7704', '11512', '1097', '14060', '769', '7152', '2420', '3992', '2840', '8774', '82060', '7358', '1893', '39172', '78542', '2418', '7956', '9236', '4529', '9838', '597', '11388', '208471', '2088', '8780', '9652', '6087', '2427', '7969', '11727', '40185', '36105', '44717', '5430', '7367', '49008', '5868', '7703', '34236', '904', '31744', '8579', '75606', '20404', '52024', '1400', '10057', '2285', '3959', '18008', '10265', '1632', '74720', '6073', '3501', '75296', '10601', '1256', '208218', '1858', '6241', '7393', '9209', '3733', '9058', '10662', '10450', '21317', '31185', '2682', '1463', '10808', '6646', '17211', '3334', '993', '109386', '26764', '3106', '11112', '2212', '6480', '7552', '11320', '25115', '7136', '22754', '3596', '5661', '63156', '2676', '45807', '86665', '208412', '7599', '3905', '9403', '23827', '9631', '37629', '1804', '5498', '125517', '9067', '18430', '11549', '36965', '7109', '7935', '9093', '500', '2823', '958', '8525', '5454', '7303', '7131', '8179', '538', '2443', '10691', '34252', '2027', '11327', '206544', '57700', '5030', '2215', '994', '79867', '7793', '3333', '53730', '2685', '47330', '9863', '3565', '18408', '1232', '5692', '103442', '2824', '5659', '507', '8374', '37078', '9060', '2488', '10468', '1803', '128801', '9636', '4915', '1669', '9404', '12569', '74786', '25124', '5234', '66243', '956', '2011', '27025', '11547', '5650', '22765', '49892', '8389', '10461', '1204', '4776', '8987', '4312', '139522', '3137', '12560', '1452', '3598', '37886', '11578', '50148', '9290', '703', '1499', '5039', '34855', '43309', '117848', '38650', '54944', '6648', '84331', '393', '3934', '9432', '10208', '68776', '4749', '1835', '9264', '3302', '4127', '1667', '14690', '4315', '18861', '3130', '23644', '65051', '3554', '6214', '1031', '4543', '45664', '5491', '7100', '72012', '2472', '3792', '14032', '5465', '6684', '5001', '1693', '82238', '951', '10459', '1832', '6825', '127276', '2029', '92095', '5802', '36739', '7769', '8721', '4588', '13228', '121347', '9899', '8177', '596', '9839', '59250', '83523', '1866', '3369', '9653', '10855', '10069', '4970', '119149', '11389', '2089', '9461', '3967', '11973', '5856', '4984', '87721', '3993', '2419', '8123', '7957', '7359', '1892', '5293', '4341', '1633', '15524', '4173', '10056', '1401', '11184', '10432', '3732', '17617', '6240', '7392', '80997', '6072', '9806', '113028', '5431', '11514', '1091', '2614', '2426', '7968', '136995', '6086', '5603', '11726', '78924', '2042', '7530', '905', '11342', '4187', '11170', '9698', '757', '1895', '88904', '39174', '565', '8124', '66228', '25973', '8540', '7508', '127487', '4983', '56449', '9466', '9654', '5099', '9230', '14896', '9002', '3538', '10899', '11177', '2277', '3197', '902', '89683', '2421', '197142', '5436', '768', '2613', '9801', '6075', '111778', '35772', '10607', '7395', '4174', '24264', '4948', '9459', '107279', '6411', '28666', '5269', '10890', '5867', '39370', '79692', '6088', '7992', '9034', '6840', '12965', '133421', '2884', '6418', '3956', '45854', '63798', '5893', '10058', '9662', '38893', '66645', '1292', '11717', '7959', '7165', '72245', '7357', '6285', '5400', '87945', '15185', '33675', '2241', '10093', '5256', '2073', '8549', '3367', '6615', '35112', '10255', '1602', '2087', '6427', '119523', '4714', '1266', '20898', '9837', '9239', '4526', '10863', '4946', '1408', '92231', '18232', '2883', '3951', '3509', '41897', '51837', '792', '92655', '554', '15981', '766', '10897', '11179', '5860', '33229', '9691', '19314', '80700', '2877', '10299', '3704', '6276', '15344', '76424', '6878', '4377', '11380', '3152', '6420', '8788', '4145', '5097', '10060', '36556', '5251', '2074', '43353', '933', '145835', '93926', '5635', '7162', '16675', '3682', '10582', '75115', '7010', '8864', '419', '5323', '72566', '2106', '2334', '11034', '15494', '5111', '41582', '6760', '9728', '3212', '1545', '10112', '4037', '1121', '25691', '10744', '11696', '4661', '35631', '3444', '2596', '121633', '77219', '6599', '2139', '7813', '8067', '20926', '142705', '4498', '13338', '43448', '8093', '9141', '6935', '1922', '86929', '79713', '4008', '80686', '18340', '35864', '3823', '9525', '11691', '4666', '8897', '6131', '81906', '2591', '6303', '3671', '8299', '1126', '5586', '4454', '12642', '86549', '105658', '1770', '4202', '35252', '7487', '3027', '11033', '5116', '135805', '11201', '1784', '118113', '16024', '7473', '5740', '7017', '2565', '5572', '9522', '10318', '4833', '100315', '29400', '9710', '1119', '15800', '9374', '97060', '8094', '6932', '4659', '11468', '28142', '2768', '77448', '38586', '1589', '82122', '1574', '74466', '4006', '9719', '205017', '73471', '3011', '4234', '6107', '3475', '10775', '4650', '5782', '4462', '26025', '8855', '428', '11653', '75124', '5544', '7213', '1580', '11005', '203314', '7677', '2305', '870', '2137', '10578', '1913', '6138', '9170', '18143', '9514', '13799', '2934', '8432', '19257', '8600', '5923', '11806', '145723', '113196', '5749', '6590', '877', '2130', '11230', '25005', '5315', '7670', '2302', '4491', '82548', '37396', '31061', '9980', '8852', '6332', '47015', '30147', '4657', '5785', '10316', '4001', '34183', '73644', '7019', '9183', '622', '76799', '8263', '112615', '11801', '848', '6769', '4802', '10927', '37739', '10329', '33997', '7489', '3029', '9513', '8899', '6903', '31896', '30178', '8297', '1914', '15891', '1188', '28127', '444', '10987', '8653', '2369', '8495', '10973', '1518', '204995', '682', '3284', '31451', '2356', '5173', '82944', '2164', '16041', '2958', '85953', '36022', '11600', '1385', '12085', '43415', '649', '7240', '4603', '81963', '9920', '6366', '28588', '6702', '5187', '15402', '4055', '40600', '4267', '21405', '3042', '9578', '6530', '208135', '4409', '685', '10974', '3248', '9772', '83092', '2960', '2538', '6198', '82524', '115007', '79782', '4260', '10345', '11297', '35230', '3879', '23355', '3277', '6705', '73617', '23167', '1520', '4436', '21254', '86973', '75184', '4604', '10721', '205615', '6153', '2735', '6395', '5510', '39851', '11607', '80842', '5346', '2163', '13534', '824', '5948', '9744', '8696', '5189', '10942', '4867', '4269', '9576', '18121', '3870', '10728', '3428', '6966', '481', '81151', '6368', '1971', '14986', '8034', '8808', '8206', '2358', '83898', '5941', '2956', '3884', '3417', '9911', '6165', '4632', '10717', '1340', '207174', '6501', '51743', '100970', '5384', '24146', '4064', '1516', '2393', '31494', '3087', '23397', '2969', '812', '7427', '5370', '10387', '10989', '11067', '1186', '11403', '2531', '7043', '16414', '8457', '11863', '4894', '5946', '49126', '640', '39251', '94642', '472', '6995', '97201', '17738', '4438', '84424', '73873', '86717', '6539', '8691', '101294', '129263', '11636', '207187', '1181', '41710', '5979', '61317', '7612', '2152', '3080', '815', '10380', '11094', '2394', '3246', '204392', '3074', '10374', '3410', '6162', '1347', '10710', '1175', '35457', '6350', '9149', '4656', '24546', '10773', '4464', '10541', '10919', '37707', '14585', '4000', '10125', '1572', '93299', '6757', '6565', '882', '10317', '5126', '1586', '8639', '7443', '20576', '15691', '11231', '2555', '8853', '7027', '10787', '29602', '81551', '9720', '18377', '4803', '8296', '81307', '1915', '1129', '4669', '2758', '623', '22448', '36048', '9182', '8050', '13559', '849', '5925', '11460', '7212', '2552', '61525', '8854', '5777', '2136', '16013', '14744', '40494', '11004', '13753', '3010', '19893', '4235', '4007', '10122', '3222', '6750', '4463', '6334', '48867', '18519', '6106', '10774', '8601', '5922', '25800', '11209', '8433', '115260', '8057', '624', '78605', '129836', '11699', '9171', '18526', '36289', '1912', '10921', '4804', '1785', '847', '93852', '7472', '8608', '6792', '7640', '2756', '11456', '41114', '11664', '2564', '50254', '3670', '35405', '6302', '73210', '1127', '1315', '11690', '9944', '1771', '3026', '6554', '7486', '6766', '21653', '10928', '75583', '1543', '10114', '8061', '420', '7029', '10789', '83495', '5128', '123162', '66963', '1588', '99759', '102685', '8405', '878', '10917', '83839', '9523', '114714', '3825', '94280', '6933', '86113', '1118', '84644', '47826', '9375', '6761', '15461', '4036', '10113', '1544', '1776', '10321', '6553', '10745', '11697', '31290', '3445', '43482', '6305', '5580', '4452', '25690', '5746', '36041', '4694', '24584', '8059', '204757', '418', '7011', '3683', '106813', '11809', '5322', '1782', '3648', '9372', '9140', '6108', '24917', '1749', '9716', '2138', '8402', '6598', '11238', '5913', '7678', '4499', '8254', '615', '8066', '427', '13937', '9988', '9928', '487', '6960', '29036', '4439', '8690', '3278', '22886', '4861', '91593', '11298', '203189', '6538', '2198', '8664', '118942', '5349', '2950', '9584', '19001', '8032', '85503', '2508', '6994', '473', '47881', '1983', '6507', '48668', '12422', '3075', '204393', '10375', '4250', '5382', '11095', '2395', '115498', '3247', '10523', '1948', '6351', '12274', '12046', '3411', '1180', '11405', '5520', '49924', '8831', '2537', '27355', '8469', '69349', '5376', '11061', '4096', '646', '96113', '6993', '474', '2957', '3885', '2359', '8663', '11059', '3871', '10943', '9321', '1970', '203377', '4091', '5143', '64663', '7614', '2968', '2154', '3086', '75711', '8836', '7042', '6190', '2530', '11630', '1187', '91907', '22412', '8238', '2702', '13193', '1341', '4633', '1173', '4401', '6356', '3624', '1517', '88486', '1725', '24147', '2961', '84084', '8467', '134385', '5378', '5976', '4098', '95592', '6199', '442', '2539', '7877', '11639', '684', '7883', '1348', '116445', '3847', '6509', '141574', '10149', '5723', '132429', '7848', '13363', '11434', '5511', '7622', '5949', '10182', '11050', '5175', '11262', '14710', '825', '4053', '11296', '4261', '3878', '138583', '3044', '30743', '1377', '4605', '3420', '6360', '9328', '4437', '5985', '4857', '140693', '18323', '7884', '3418', '41986', '1941', '683', '12887', '80047', '8838', '7870', '31239', '1189', '677', '5971', '78232', '9780', '28770', '77874', '8460', '10388', '39430', '14728', '6367', '29803', '1142', '10515', '4602', '45525', '9921', '6155', '7087', '3427', '10343', '1714', '11291', '2191', '9579', '6703', '11265', '4292', '2959', '822', '13532', '6393', '31808', '124779', '11601', '1384', '7073', '2381', '11081', '4076', '1736', '5396', '16096', '3061', '1352', '10705', '20190', '4620', '6177', '3405', '18568', '205403', '10537', '1160', '4412', '5706', '6183', '458', '46144', '1194', '5534', '2375', '4082', '800', '2147', '81371', '3608', '6148', '493', '9100', '15248', '97442', '8684', '3896', '2178', '9590', '33914', '5953', '7638', '69534', '467', '1399', '11240', '5365', '85977', '23382', '7432', '2140', '4085', '36650', '98290', '1193', '123579', '8822', '6342', '23520', '54472', '699', '4415', '4627', '9904', '9138', '40416', '1731', '4243', '125810', '6726', '2386', '10154', '7069', '7855', '27379', '460', '91110', '11429', '6389', '8213', '4886', '5954', '5168', '96751', '8677', '80406', '3891', '19012', '58422', '4872', '51769', '9563', '18134', '144024', '3059', '38533', '9107', '494', '52588', '1158', '75198', '1964', '9335', '7252', '2720', '7060', '11612', '11276', '5353', '10196', '25271', '7636', '3296', '13713', '43063', '22292', '3050', '4275', '12635', '1151', '6374', '3606', '9932', '30333', '10734', '1363', '29483', '7609', '8641', '109029', '9793', '5962', '10995', '7863', '27941', '6179', '6945', '690', '9303', '86959', '9767', '5996', '4844', '10961', '4078', '1738', '2981', '9935', '7093', '3433', '10501', '40271', '109481', '10165', '1532', '32235', '6717', '22295', '3057', '2185', '11043', '5166', '28569', '8679', '2343', '5354', '115218', '11615', '1390', '196998', '5730', '11427', '14969', '22437', '2727', '3854', '8480', '9552', '9760', '2388', '5991', '11088', '4843', '79764', '1169', '4629', '6942', '2718', '8222', '130352', '14358', '5965', '5159', '4817', '18363', '30509', '9734', '29424', '205208', '3800', '9162', '6916', '9350', '8282', '4689', '637', '11814', '6788', '2787', '3655', '26037', '6327', '59308', '11487', '10555', '4642', '5790', '6929', '3467', '6115', '4226', '33181', '32053', '896', '3231', '7691', '6743', '1566', '4828', '5300', '2125', '862', '99743', '2317', '7665', '5132', '11017', '43454', '8249', '4484', '9995', '8427', '2921', '11813', '87473', '204927', '28505', '10599', '630', '7239', '7837', '9357', '51961', '29047', '3807', '10935', '10109', '4810', '5763', '10794', '13111', '3494', '7808', '8840', '7034', '5551', '75131', '2310', '7662', '5307', '11222', '8418', '2122', '865', '7696', '1753', '6576', '891', '3460', '73000', '9966', '9368', '2780', '6320', '1105', '8075', '19422', '91712', '8411', '73499', '106231', '2917', '7459', '41769', '11019', '83223', '4228', '24138', '21678', '1930', '38331', '15815', '11489', '10769', '3469', '8081', '9153', '5103', '11026', '2114', '853', '11214', '8876', '5567', '10590', '8278', '30197', '639', '6918', '8882', '9950', '4673', '10756', '5593', '4441', '6316', '4025', '24335', '95977', '6772', '6540', '40442', '1765', '40822', '8086', '74825', '4479', '9702', '7698', '4821', '38752', '10138', '6578', '78082', '3836', '5907', '85127', '8416', '80455', '11648', '8072', '433', '22658', '601', '9392', '39210', '6547', '18964', '3809', '74670', '1762', '4022', '1550', '13782', '4446', '29875', '26001', '9359', '81914', '8885', '9957', '4674', '207132', '3697', '2745', '7237', '7839', '5752', '4680', '101448', '2113', '47694', '5336', '206470', '11021', '6781', '7402', '837', '5355', '44240', '5503', '26096', '6386', '2514', '8812', '5731', '32496', '11614', '74283', '1157', '6372', '3432', '7092', '4617', '89326', '3056', '4273', '5193', '4041', '1533', '10164', '3264', '26406', '8011', '98891', '7059', '86197', '16258', '10993', '5158', '8475', '78829', '6729', '5990', '11089', '3069', '79133', '3855', '6943', '7891', '696', '29829', '80294', '1954', '1534', '25284', '42144', '9759', '205057', '6711', '2183', '138596', '6523', '10351', '11283', '27385', '6147', '9933', '4610', '33785', '1150', '13382', '6375', '73267', '468', '2513', '22603', '5736', '7253', '10197', '2345', '7637', '2177', '86164', '6944', '9130', '7896', '5399', '1739', '12439', '9554', '2980', '35815', '5997', '5963', '49103', '5709', '457', '4626', '1354', '10703', '3403', '6171', '9905', '7291', '17714', '6343', '4414', '6727', '22097', '4070', '10969', '11087', '1502', '5390', '1730', '6515', '2989', '77261', '7601', '22063', '4084', '25848', '10393', '2141', '806', '7433', '5700', '132638', '87877', '11417', '9562', '3864', '10358', '9750', '26408', '6718', '1159', '120104', '81979', '6972', '18551', '1991', '8212', '7068', '94651', '13529', '839', '4289', '20539', '8676', '16635', '1195', '74087', '5707', '8018', '2522', '459', '8824', '13949', '10394', '2146', '3094', '801', '7434', '2374', '11074', '4245', '5397', '1737', '8488', '3252', '47407', '22090', '4077', '11080', '3636', '40246', '4621', '10704', '6176', '4880', '5952', '8443', '2945', '29681', '7853', '466', '96101', '82733', '70418', '9101', '92555', '10509', '134503', '102061', '4048', '10951', '4874', '8685', '3863', '204319', '98699', '8625', '80202', '51199', '8241', '13922', '8073', '7807', '432', '2549', '74018', '1936', '4478', '9155', '3837', '9703', '10905', '7004', '7838', '5753', '37186', '11444', '36266', '5939', '5105', '7652', '2320', '855', '7460', '85119', '8428', '203103', '1551', '4023', '3808', '4211', '3450', '1307', '10562', '1135', '37340', '4447', '17747', '108530', '9358', '1569', '10902', '29242', '9152', '97246', '114157', '2788', '82760', '435', '27922', '2318', '5901', '8410', '10565', '5592', '4440', '6317', '3665', '2585', '6919', '10757', '113943', '73453', '9509', '125845', '10333', '4216', '1556', '10101', '6773', '2929', '852', '7467', '2115', '145168', '11027', '2327', '10591', '11443', '7231', '23581', '638', '8877', '140842', '11671', '133571', '9164', '6910', '1309', '112296', '205458', '10934', '107112', '9500', '5937', '78274', '8614', '18391', '2920', '49701', '1799', '7836', '8042', '11678', '33528', '127185', '44648', '7238', '631', '10305', '4220', '3839', '890', '7697', '73657', '6745', '1560', '4012', '2781', '3653', '11481', '1104', '208378', '1938', '24554', '36091', '4644', '9967', '30366', '8089', '114996', '7207', '13322', '2775', '11475', '11647', '9993', '22657', '11223', '864', '8419', '2123', '16234', '7663', '5908', '11011', '5134', '115272', '8421', '11029', '9735', '1900', '9351', '84660', '2316', '41766', '11016', '5301', '6584', '2918', '2124', '11640', '10792', '8846', '7032', '76580', '7200', '2772', '205494', '11472', '5557', '6114', '9960', '6928', '3466', '2786', '4471', '6742', '10130', '4015', '4227', '144843', '897', '6570', '42065', '6630', '23052', '1415', '10042', '37452', '36580', '16187', '4731', '1243', '48309', '7988', '3514', '92648', '3726', '6254', '7386', '4503', '21361', '1071', '5617', '11732', '549', '8108', '6092', '8934', '2600', '75879', '5425', '2264', '7716', '4193', '11164', '5273', '11356', '2056', '911', '18674', '9223', '6865', '103291', '6059', '42268', '208464', '1618', '8795', '23851', '2069', '11369', '4990', '8761', '7943', '5628', '89697', '5274', '11351', '916', '2263', '4194', '41613', '2607', '5422', '1082', '15395', '11735', '50305', '3721', '143579', '4504', '4736', '10613', '4352', '1620', '6405', '2899', '3345', '10879', '4160', '10045', '83957', '571', '8130', '13861', '33668', '2638', '104611', '5845', '4997', '19331', '48593', '43349', '9486', '4399', '10846', '4963', '84143', '17851', '585', '4709', '40960', '1875', '9224', '133631', '70506', '2631', '8905', '7171', '1286', '25536', '2067', '77175', '4390', '52000', '5242', '11367', '206504', '44357', '10087', '2093', '4364', '88787', '5084', '25394', '40703', '1424', '3373', '6601', '4532', '10417', '3717', '6265', '108677', '6057', '4700', '9682', '96676', '2058', '8562', '16941', '5619', '7972', '547', '7986', '136147', '6068', '3728', '1843', '10428', '9676', '5887', '1629', '9444', '2890', '3942', '7182', '73142', '1275', '4535', '90915', '3710', '5083', '10074', '205140', '107852', '2094', '6434', '21501', '101997', '11394', '10246', '203243', '11152', '4999', '2252', '4397', '11360', '81893', '6898', '8902', '5621', '39952', '11704', '5413', '14878', '2636', '90740', '8591', '2897', '3945', '23867', '6639', '203288', '122918', '10877', '4952', '786', '1844', '1078', '49014', '33659', '7975', '52038', '58502', '134287', '203872', '918', '16348', '82043', '10883', '141610', '9625', '29707', '3911', '4308', '32941', '3549', '6807', '10649', '38211', '28083', '9241', '514', '9087', '85464', '34428', '8367', '726', '11139', '6699', '27669', '25902', '14679', '3744', '2696', '18629', '1013', '62064', '1221', '5681', '74757', '4337', '987', '6460', '17037', '84119', '7780', '3320', '10020', '1477', '4105', '14480', '5211', '2808', '2206', '5023', '14474', '34417', '2662', '719', '5675', '8956', '7122', '9884', '2450', '2830', '8536', '1689', '143386', '5827', '8704', '10488', '3788', '109508', '721', '9246', '9848', '9074', '6800', '6458', '80581', '9410', '10018', '79242', '3318', '10685', '7125', '31162', '79289', '2201', '1484', '10027', '10215', '1642', '4330', '3929', '3115', '5686', '113059', '3571', '8199', '3743', '9279', '4566', '717', '8356', '20019', '8958', '43779', '525', '8732', '5811', '135102', '4339', '17039', '48701', '34089', '23802', '95859', '6238', '79610', '114047', '6697', '106911', '2839', '64500', '1680', '7113', '2461', '13036', '5644', '10481', '5476', '728', '2653', '3781', '22785', '76455', '5482', '6207', '10011', '4908', '75486', '6663', '81668', '23001', '12746', '79845', '83751', '4568', '3329', '145286', '4930', '3927', '6469', '9421', '105790', '82213', '18082', '522', '72805', '7319', '710', '7584', '18049', '1441', '6664', '3316', '1025', '5485', '1819', '6200', '9248', '3772', '9846', '1217', '10640', '4765', '5471', '89092', '7326', '2654', '204460', '3786', '7114', '43741', '11766', '4791', '945', '2002', '1687', '11302', '5227', '77322', '2230', '27452', '926', '17096', '7513', '2061', '5244', '11153', '7721', '72633', '8769', '5412', '7345', '26187', '2637', '50335', '2405', '1280', '11705', '74968', '86871', '4534', '6263', '7183', '6051', '9825', '4706', '6435', '2095', '3147', '42260', '4362', '10075', '1422', '60302', '3375', '8100', '91031', '15994', '11508', '63914', '9684', '5875', '11950', '10882', '919', '2862', '10876', '2896', '4739', '12977', '60759', '1079', '15960', '1845', '10072', '4157', '5085', '16385', '15732', '203083', '9822', '4701', '15958', '4533', '99290', '22712', '8904', '579', '11702', '5627', '5415', '11154', '10086', '22144', '2254', '3988', '2066', '27604', '11366', '4391', '3729', '780', '95650', '1628', '112585', '5288', '8597', '5886', '24278', '24882', '126744', '2059', '8563', '133296', '80712', '9683', '8751', '5872', '10885', '8335', '774', '75278', '36923', '8107', '18482', '4737', '9814', '9028', '99094', '3512', '76400', '23430', '7380', '76632', '1077', '4505', '35131', '73724', '12713', '30443', '10044', '4353', '2898', '3176', '5047', '4195', '52205', '41420', '5275', '52037', '23292', '2050', '207085', '5611', '2434', '13063', '7374', '2606', '1083', '3975', '9473', '10249', '90542', '4962', '10847', '6609', '8793', '9641', '1874', '9225', '584', '4708', '27867', '6299', '570', '7945', '80516', '78135', '9487', '4398', '2601', '21394', '70536', '548', '8109', '5272', '910', '3185', '2057', '7717', '11165', '1626', '3171', '5888', '44393', '21704', '4166', '3727', '29931', '10427', '15155', '4502', '1242', '6067', '18478', '7989', '5843', '4991', '7728', '3388', '8760', '109108', '2068', '11368', '577', '20877', '5629', '1887', '8304', '99890', '1873', '9222', '3718', '4965', '10840', '8794', '9646', '3972', '9474', '5219', '85037', '18083', '2800', '5817', '7318', '83596', '82444', '2458', '115355', '9276', '51840', '1827', '5689', '81007', '26778', '3926', '3328', '81651', '10814', '83106', '2467', '7929', '4790', '5642', '11767', '11555', '126974', '5828', '72463', '944', '1686', '11303', '4132', '1440', '10017', '6665', '141618', '3125', '23235', '6033', '8995', '4764', '24474', '1216', '40131', '4556', '1818', '5484', '1024', '9249', '73313', '19390', '10813', '4936', '74758', '9427', '988', '10679', '9043', '9271', '6239', '1820', '524', '8165', '65088', '9285', '716', '8357', '104220', '2209', '204801', '69013', '93969', '7549', '2807', '5483', '10474', '40304', '3774', '6808', '2494', '6034', '8992', '10646', '3122', '9418', '6450', '17007', '1675', '68338', '207441', '4135', '10010', '4909', '6662', '78398', '2004', '943', '206567', '11304', '27454', '87932', '5477', '729', '16777', '2460', '9088', '50350', '7112', '5645', '75225', '41010', '91259', '6801', '48352', '1218', '86213', '4558', '128028', '10019', '9623', '9411', '3917', '15759', '34876', '12588', '25904', '94346', '105592', '5228', '8153', '2469', '66409', '10489', '8361', '3789', '7329', '3114', '141629', '10026', '9278', '6230', '1829', '4567', '1015', '11590', '1227', '10670', '9876', '2664', '5441', '11564', '3584', '8950', '5217', '975', '6492', '20647', '1485', '8366', '727', '49273', '85465', '4799', '83792', '7578', '14678', '207689', '91401', '5821', '2238', '6698', '28412', '86670', '8392', '9240', '6208', '9072', '2207', '12782', '11107', '2035', '124843', '85802', '2809', '972', '5674', '10683', '7123', '718', '7311', '10677', '1220', '3577', '9871', '6005', '138282', '15553', '10021', '134219', '38479', '3113']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "directory = './images/train/'\n",
    "chains = []\n",
    "for chain in range(-1,93):\n",
    "    chains.append(directory+str(chain))\n",
    "chains\n",
    "def hotel_split(chains):\n",
    "    \n",
    "    for chain in chains:\n",
    "        locations = [chain+'/'+f for f in os.listdir(chain)]\n",
    "        for location in locations:\n",
    "            if 'travel_website' in os.listdir(location):\n",
    "                travelwebsite = location+'/'+'travel_website'\n",
    "                # now we want to grab 20% of the images from travel website\n",
    "                images = [travelwebsite+'/'+f for f in os.listdir(travelwebsite)]\n",
    "                for image in images:\n",
    "                    #generate a rand num so 20% of the time it will satisfy a condition\n",
    "                    x = random.rand()\n",
    "                    if x <= .2:\n",
    "                        # then copy image to another folder test 20%\n",
    "                        \n",
    "                        # else copy image to another folder train 80%\n",
    "\n",
    "hotel_images(chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/lauranguyen/Desktop/Galvanize/capstones/Hotels-50K/images/train/1/3928997.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-f687aebbda23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#shutil.copy(source file from images list, destination file) file from images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./images/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0;31m# macOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/lauranguyen/Desktop/Galvanize/capstones/Hotels-50K/images/train/1/3928997.jpg'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "images = []\n",
    "for _,_,files in os.walk(\"./images/train/1\"):\n",
    "    for name in files:\n",
    "        images.append(os.path.join(\"./images/train/1\", name))\n",
    "images\n",
    "#shutil.copy(source file from images list, destination file) file from images\n",
    "shutil.copy(images[2], './images/'+images[2].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./images/3897091.jpg'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'./images/'+images[1].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lauranguyen/Desktop/Galvanize/capstones/Hotels-50K\r\n"
     ]
    }
   ],
   "source": [
    "find . -type f -print0 | xargs -0 mv -t ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chain in range(-1,93):\n",
    "#         print(directory+str(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m10238\u001b[m\u001b[m \u001b[34m1708\u001b[m\u001b[m  \u001b[34m1805\u001b[m\u001b[m  \u001b[34m33978\u001b[m\u001b[m \u001b[34m38431\u001b[m\u001b[m \u001b[34m694\u001b[m\u001b[m   \u001b[34m7149\u001b[m\u001b[m  \u001b[34m7623\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./images/train/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1M Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 171088 images belonging to 90 classes.\n",
      "Found 42729 images belonging to 90 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width = 640\n",
    "img_height = 360\n",
    "batch_size =10\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255,\n",
    "                validation_split=0.2)\n",
    "\n",
    "\n",
    "# The generator object. \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './images/train',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    './images/train',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 640, 360\n",
    "\n",
    "nb_train_samples = 171088\n",
    "nb_validation_samples = 42729\n",
    "epochs = 5\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(640, 360, 3)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(90,\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=keras.regularizers.l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3421/3421 [==============================] - 3680s 1s/step - loss: 3.0307 - accuracy: 0.5095 - val_loss: 2.5701 - val_accuracy: 0.5245\n",
      "Epoch 2/5\n",
      "3421/3421 [==============================] - 3706s 1s/step - loss: 2.5884 - accuracy: 0.5244 - val_loss: 2.6558 - val_accuracy: 0.4883\n",
      "Epoch 3/5\n",
      "3421/3421 [==============================] - 3609s 1s/step - loss: 2.5186 - accuracy: 0.5258 - val_loss: 2.7740 - val_accuracy: 0.4769\n",
      "Epoch 4/5\n",
      "3421/3421 [==============================] - 3642s 1s/step - loss: 2.4649 - accuracy: 0.5316 - val_loss: 3.7027 - val_accuracy: 0.4334\n",
      "Epoch 5/5\n",
      "3421/3421 [==============================] - 4114s 1s/step - loss: 2.4502 - accuracy: 0.5280 - val_loss: 3.1841 - val_accuracy: 0.4399\n"
     ]
    }
   ],
   "source": [
    "# mod = model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=nb_train_samples // batch_size,\n",
    "#         epochs=epochs,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "# DO NOT RE-RUN -- TAKES 5 HOURS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without 'Unknown' Hotel Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80817 images belonging to 89 classes.\n",
      "Found 20162 images belonging to 89 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width = 640\n",
    "img_height = 360\n",
    "batch_size =50\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255,\n",
    "                validation_split=0.2)\n",
    "\n",
    "\n",
    "# The generator object. \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './images/train',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    './images/train',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 640, 360\n",
    "\n",
    "nb_train_samples = 80817\n",
    "nb_validation_samples = 20162\n",
    "epochs = 5\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(640, 360, 3)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(89,\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=keras.regularizers.l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   8/1616 [..............................] - ETA: 5:28:56 - loss: 10.0712 - accuracy: 0.0112"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-0bfbda6cac3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m mod_no_unk = model.fit_generator(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_train_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[0;32m-> 1847\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1848\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mod_no_unk = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Chains Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0 best western, 75 motel 6, 2 marriott, 3 hilton, 1 hyatt, 86 la quinta, 57 travellodge, \n",
    "#47 kimpton, 64 candelwood suites, 60 wyndham, 71 crowne plaza, 72 extended stay america, \n",
    "# 73, ramada, 74 embassy suites, 70 econo lodge, 67 red roof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14085 images belonging to 6 classes.\n",
      "Found 3520 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width = 640\n",
    "img_height = 360\n",
    "batch_size = 10\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255,\n",
    "                validation_split=0.2)\n",
    "\n",
    "\n",
    "# The generator object. \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './images/top_chains',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    './images/top_chains',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 640, 360\n",
    "\n",
    "nb_train_samples = 14085\n",
    "nb_validation_samples = 3520\n",
    "epochs = 5\n",
    "batch_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(640, 360, 3)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(6,\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=keras.regularizers.l2(0.0001)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "939/939 [==============================] - 1113s 1s/step - loss: 2.8114 - accuracy: 0.2352 - val_loss: 1.8267 - val_accuracy: 0.2278\n",
      "Epoch 2/5\n",
      "939/939 [==============================] - 1175s 1s/step - loss: 1.6645 - accuracy: 0.3004 - val_loss: 2.2616 - val_accuracy: 0.2504\n",
      "Epoch 3/5\n",
      "939/939 [==============================] - 1045s 1s/step - loss: 1.5110 - accuracy: 0.3974 - val_loss: 2.3916 - val_accuracy: 0.2376\n",
      "Epoch 4/5\n",
      "939/939 [==============================] - 1121s 1s/step - loss: 1.2702 - accuracy: 0.5233 - val_loss: 3.2426 - val_accuracy: 0.2312\n",
      "Epoch 5/5\n",
      "939/939 [==============================] - 1359s 1s/step - loss: 1.0315 - accuracy: 0.6211 - val_loss: 3.9498 - val_accuracy: 0.2286\n"
     ]
    }
   ],
   "source": [
    "mod_top_chains = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_98 (Conv2D)           (None, 638, 358, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling (None, 319, 179, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 317, 177, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_98 (MaxPooling (None, 158, 88, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 444928)            0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 64)                28475456  \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 28,485,990\n",
      "Trainable params: 28,485,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "#### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 640, 360\n",
    "\n",
    "nb_train_samples = 14085\n",
    "nb_validation_samples = 3520\n",
    "epochs = 5\n",
    "batch_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod2 = keras.models.Sequential()\n",
    "mod2.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(640, 360, 3)))\n",
    "mod2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "# model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mod2.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "mod2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mod2.add(keras.layers.Flatten())\n",
    "mod2.add(keras.layers.Dense(64, activation='relu'))\n",
    "mod2.add(keras.layers.Dropout(0.5))\n",
    "mod2.add(keras.layers.Dense(6,\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=keras.regularizers.l2(0.0001)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "939/939 [==============================] - 2674s 3s/step - loss: 3.0703 - accuracy: 0.2197 - val_loss: 1.7446 - val_accuracy: 0.2410\n",
      "Epoch 2/5\n",
      "148/939 [===>..........................] - ETA: 59:07 - loss: 1.7432 - accuracy: 0.2437"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-288-2d4885acd3d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m mod_top_chains2 = mod2.fit_generator(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_train_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[0;32m-> 1847\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1848\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mod_top_chains2 = mod2.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_96 (Conv2D)           (None, 638, 358, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling (None, 319, 179, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 317, 177, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling (None, 158, 88, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 889856)            0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 64)                56950848  \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 56,970,630\n",
      "Trainable params: 56,970,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. \n",
    "Great training performance, however the validation loss decreases or fluctuates wildly while the validation accuracy stays around 23 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 640, 360\n",
    "\n",
    "nb_train_samples = 14085\n",
    "nb_validation_samples = 3520\n",
    "epochs = 10\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod3 = keras.models.Sequential()\n",
    "mod3.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(640, 360, 3)))\n",
    "mod3.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "# model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mod3.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "mod3.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mod3.add(keras.layers.Flatten())\n",
    "mod3.add(keras.layers.Dense(64, activation='relu'))\n",
    "mod3.add(keras.layers.Dropout(0.6))\n",
    "mod3.add(keras.layers.Dense(6,\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=keras.regularizers.l2(0.0001)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "563/563 [==============================] - 1033s 2s/step - loss: 3.9877 - accuracy: 0.2307 - val_loss: 1.7561 - val_accuracy: 0.2321\n",
      "Epoch 2/10\n",
      "563/563 [==============================] - 904s 2s/step - loss: 1.7594 - accuracy: 0.2272 - val_loss: 1.7382 - val_accuracy: 0.2407\n",
      "Epoch 3/10\n",
      "563/563 [==============================] - 1092s 2s/step - loss: 1.7383 - accuracy: 0.2442 - val_loss: 1.7463 - val_accuracy: 0.2336\n",
      "Epoch 4/10\n",
      "563/563 [==============================] - 1369s 2s/step - loss: 1.7048 - accuracy: 0.2554 - val_loss: 1.9695 - val_accuracy: 0.2486\n",
      "Epoch 5/10\n",
      "563/563 [==============================] - 3688s 7s/step - loss: 1.6424 - accuracy: 0.3156 - val_loss: 2.0356 - val_accuracy: 0.2364\n",
      "Epoch 6/10\n",
      "563/563 [==============================] - 2835s 5s/step - loss: 1.5937 - accuracy: 0.3489 - val_loss: 2.2763 - val_accuracy: 0.2471\n",
      "Epoch 7/10\n",
      "563/563 [==============================] - 2009s 4s/step - loss: 1.5423 - accuracy: 0.3749 - val_loss: 2.3454 - val_accuracy: 0.2564\n",
      "Epoch 8/10\n",
      "563/563 [==============================] - 1581s 3s/step - loss: 1.4733 - accuracy: 0.4155 - val_loss: 3.2173 - val_accuracy: 0.2193\n",
      "Epoch 9/10\n",
      "563/563 [==============================] - 1813s 3s/step - loss: 1.3871 - accuracy: 0.4535 - val_loss: 2.7831 - val_accuracy: 0.2514\n",
      "Epoch 10/10\n",
      "563/563 [==============================] - 975s 2s/step - loss: 1.2997 - accuracy: 0.4845 - val_loss: 2.9609 - val_accuracy: 0.2336\n"
     ]
    }
   ],
   "source": [
    "mod_top_chains3 = mod3.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_94 (Conv2D)           (None, 638, 358, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling (None, 319, 179, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 317, 177, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling (None, 158, 88, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 889856)            0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 64)                56950848  \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 56,970,630\n",
      "Trainable params: 56,970,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 epochs, with dropout at 0.6 worked well\n",
    "#### 3.\n",
    "Larger batch size give lower test accuracy around 24 percent and higher validation accuracy around 25 percent. Additionally, validation loss stays around 1.7 and slowly goes down with more epochs. This may be worth investing in for future iterations with more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 640, 360\n",
    "\n",
    "nb_train_samples = 14085\n",
    "nb_validation_samples = 3520\n",
    "epochs = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod4 = keras.models.Sequential()\n",
    "mod4.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(640, 360, 3)))\n",
    "mod4.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "# model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mod4.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "mod4.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mod4.add(keras.layers.Flatten())\n",
    "mod4.add(keras.layers.Dense(64, activation='relu'))\n",
    "mod4.add(keras.layers.Dropout(0.7))\n",
    "mod4.add(keras.layers.Dense(6,\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=keras.regularizers.l2(0.0001)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod4.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "140/140 [==============================] - 199s 1s/step - loss: 13.3628 - accuracy: 0.2143 - val_loss: 1.7784 - val_accuracy: 0.2429\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 269s 2s/step - loss: 1.7819 - accuracy: 0.2289 - val_loss: 1.7637 - val_accuracy: 0.2400\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 241s 2s/step - loss: 1.7609 - accuracy: 0.2315 - val_loss: 1.7495 - val_accuracy: 0.2314\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 215s 2s/step - loss: 1.7546 - accuracy: 0.2461 - val_loss: 1.7539 - val_accuracy: 0.2429\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 196s 1s/step - loss: 1.7475 - accuracy: 0.2348 - val_loss: 1.7518 - val_accuracy: 0.2600\n",
      "Epoch 6/10\n",
      "140/140 [==============================] - 185s 1s/step - loss: 1.7565 - accuracy: 0.2112 - val_loss: 1.7473 - val_accuracy: 0.2114\n",
      "Epoch 7/10\n",
      "140/140 [==============================] - 185s 1s/step - loss: 1.7352 - accuracy: 0.2429 - val_loss: 1.7636 - val_accuracy: 0.2286\n",
      "Epoch 8/10\n",
      "140/140 [==============================] - 182s 1s/step - loss: 1.7591 - accuracy: 0.2020 - val_loss: 1.7629 - val_accuracy: 0.2171\n",
      "Epoch 9/10\n",
      "140/140 [==============================] - 181s 1s/step - loss: 1.7496 - accuracy: 0.2486 - val_loss: 1.7344 - val_accuracy: 0.2571\n",
      "Epoch 10/10\n",
      "140/140 [==============================] - 183s 1s/step - loss: 1.7589 - accuracy: 0.2245 - val_loss: 1.7478 - val_accuracy: 0.2400\n"
     ]
    }
   ],
   "source": [
    "mod_top_chains4 = mod4.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_92 (Conv2D)           (None, 638, 358, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_91 (MaxPooling (None, 319, 179, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 317, 177, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling (None, 158, 88, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 889856)            0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 64)                56950848  \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 56,970,630\n",
      "Trainable params: 56,970,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.\n",
    "Lower batch size and lower epoch to see quick results. The validation accuracy is as high as 28 percent with low test accuracy around 24 percent and validation loss at the high 1.7 mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 640, 360\n",
    "\n",
    "nb_train_samples = 14085\n",
    "nb_validation_samples = 3520\n",
    "epochs = 5\n",
    "batch_size = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = keras.models.Sequential()\n",
    "mod.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(640, 360, 3)))\n",
    "mod.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mod.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "mod.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mod.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "mod.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "mod.add(keras.layers.Flatten())\n",
    "mod.add(keras.layers.Dense(64, activation='relu'))\n",
    "mod.add(keras.layers.Dropout(0.9))\n",
    "mod.add(keras.layers.Dense(6,\n",
    "                activation='softmax',\n",
    "                kernel_regularizer=keras.regularizers.l2(0.0001)))\n",
    "\n",
    "mod.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "201/201 [==============================] - 316s 2s/step - loss: 3.2778 - accuracy: 0.2234 - val_loss: 1.7716 - val_accuracy: 0.2480\n",
      "Epoch 2/5\n",
      "201/201 [==============================] - 481s 2s/step - loss: 1.7645 - accuracy: 0.2670 - val_loss: 1.7741 - val_accuracy: 0.2340\n",
      "Epoch 3/5\n",
      "201/201 [==============================] - 475s 2s/step - loss: 1.7608 - accuracy: 0.2348 - val_loss: 1.7441 - val_accuracy: 0.2820\n",
      "Epoch 4/5\n",
      "201/201 [==============================] - 557s 3s/step - loss: 1.7585 - accuracy: 0.2385 - val_loss: 1.7448 - val_accuracy: 0.2600\n",
      "Epoch 5/5\n",
      "201/201 [==============================] - 394s 2s/step - loss: 1.7540 - accuracy: 0.2381 - val_loss: 1.7514 - val_accuracy: 0.2480\n"
     ]
    }
   ],
   "source": [
    "mod_top_chains5 = mod.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_89 (Conv2D)           (None, 638, 358, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_88 (MaxPooling (None, 319, 179, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 317, 177, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_89 (MaxPooling (None, 158, 88, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 156, 86, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 78, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 214656)            0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 64)                13738048  \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 13,767,078\n",
      "Trainable params: 13,767,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
